"""
This type stub file was generated by pyright.
"""

import torchvision
from torch.utils.data import DataLoader, Dataset, dataloader

"""
Dataloaders and dataset utils
"""
HELP_URL = ...
IMG_FORMATS = ...
VID_FORMATS = ...
LOCAL_RANK = ...
RANK = ...
PIN_MEMORY = ...
def get_hash(paths): # -> str:
    ...

def exif_size(img): # -> tuple[Unknown, Unknown]:
    ...

def exif_transpose(image):
    """
    Transpose a PIL image accordingly if it has an EXIF Orientation tag.
    Inplace version of https://github.com/python-pillow/Pillow/blob/master/src/PIL/ImageOps.py exif_transpose()

    :param image: The image to transpose.
    :return: An image.
    """
    ...

def seed_worker(worker_id): # -> None:
    ...

def create_dataloader(path, imgsz, batch_size, stride, single_cls=..., hyp=..., augment=..., cache=..., pad=..., rect=..., rank=..., workers=..., image_weights=..., quad=..., prefix=..., shuffle=...): # -> tuple[DataLoader[Unknown] | InfiniteDataLoader, LoadImagesAndLabels]:
    ...

class InfiniteDataLoader(dataloader.DataLoader):
    """ Dataloader that reuses workers

    Uses same syntax as vanilla DataLoader
    """
    def __init__(self, *args, **kwargs) -> None:
        ...
    
    def __len__(self): # -> int:
        ...
    
    def __iter__(self): # -> Generator[Any, None, None]:
        ...
    


class _RepeatSampler:
    """ Sampler that repeats forever

    Args:
        sampler (Sampler)
    """
    def __init__(self, sampler) -> None:
        ...
    
    def __iter__(self): # -> Generator[Unknown, None, None]:
        ...
    


class LoadScreenshots:
    def __init__(self, source, img_size=..., stride=..., auto=..., transforms=...) -> None:
        ...
    
    def __iter__(self): # -> Self@LoadScreenshots:
        ...
    
    def __next__(self): # -> tuple[str, Unknown | NDArray[Any], ndarray[Any, dtype[Unknown]], None, str]:
        ...
    


class LoadImages:
    def __init__(self, path, img_size=..., stride=..., auto=..., transforms=..., vid_stride=...) -> None:
        ...
    
    def __iter__(self): # -> Self@LoadImages:
        ...
    
    def __next__(self): # -> tuple[Unknown, Unknown | NDArray[Any], Unknown | Mat, Unknown | None, str]:
        ...
    
    def __len__(self): # -> int:
        ...
    


class LoadStreams:
    def __init__(self, sources=..., img_size=..., stride=..., auto=..., transforms=..., vid_stride=...) -> None:
        ...
    
    def update(self, i, cap, stream): # -> None:
        ...
    
    def __iter__(self): # -> Self@LoadStreams:
        ...
    
    def __next__(self): # -> tuple[list[str], NDArray[Unknown] | NDArray[Any], list[None], None, Literal['']]:
        ...
    
    def __len__(self): # -> int:
        ...
    


def img2label_paths(img_paths): # -> list[str]:
    ...

class LoadImagesAndLabels(Dataset):
    cache_version = ...
    rand_interp_methods = ...
    def __init__(self, path, img_size=..., batch_size=..., augment=..., hyp=..., rect=..., image_weights=..., cache_images=..., single_cls=..., stride=..., pad=..., min_items=..., prefix=..., workers=...) -> None:
        ...
    
    def check_cache_ram(self, safety_margin=..., prefix=...): # -> bool:
        ...
    
    def cache_labels(self, path=..., prefix=...): # -> dict[Unknown, Unknown]:
        ...
    
    def __len__(self): # -> int:
        ...
    
    def __getitem__(self, index): # -> tuple[Tensor, Tensor, Unknown, tuple[tuple[Any | int | Unknown, Any | int | Unknown], tuple[tuple[Any | float | Unknown, Any | float | Unknown], tuple[Any | float | Unknown, Any | float | Unknown]]] | None]:
        ...
    
    def load_image(self, i): # -> tuple[Mat | Any, tuple[Any | int, Any | int], tuple[int, ...] | Any] | tuple[Unknown, Unknown, Unknown]:
        ...
    
    def cache_images_to_disk(self, i): # -> None:
        ...
    
    def load_mosaic(self, index): # -> tuple[Any | Unknown, Unknown]:
        ...
    
    def load_mosaic9(self, index): # -> tuple[Any | Unknown, Unknown]:
        ...
    
    @staticmethod
    def collate_fn(batch): # -> tuple[Tensor, Tensor, Unknown, Unknown]:
        ...
    
    @staticmethod
    def collate_fn4(batch): # -> tuple[Tensor, Tensor, Unknown, Unknown]:
        ...
    


def flatten_recursive(path=...): # -> None:
    ...

def extract_boxes(path=...): # -> None:
    ...

def autosplit(path=..., weights=..., annotated_only=...): # -> None:
    """ Autosplit a dataset into train/val/test splits and save path/autosplit_*.txt files
    Usage: from yolov5.utils.dataloaders import *; autosplit()
    Arguments
        path:            Path to images directory
        weights:         Train, val, test weights (list, tuple)
        annotated_only:  Only use images with an annotated txt file
    """
    ...

def verify_image_label(args): # -> tuple[Unknown, ndarray[Any, dtype[float32]], tuple[int, int], list[Unknown] | list[ndarray[Any, dtype[float32]]], Literal[0, 1], Literal[1, 0], Literal[0, 1], Literal[0], str] | list[int | str | None]:
    ...

class HUBDatasetStats:
    """ Class for generating HUB dataset JSON and `-hub` dataset directory

    Arguments
        path:           Path to data.yaml or data.zip (with data.yaml inside data.zip)
        autodownload:   Attempt to download dataset if not found locally

    Usage
        from yolov5.utils.dataloaders import HUBDatasetStats
        stats = HUBDatasetStats('coco128.yaml', autodownload=True)  # usage 1
        stats = HUBDatasetStats('path/to/coco128.zip')  # usage 2
        stats.get_json(save=False)
        stats.process_images()
    """
    def __init__(self, path=..., autodownload=...) -> None:
        ...
    
    def get_json(self, save=..., verbose=...): # -> dict[str, Any | list[Any]]:
        ...
    
    def process_images(self): # -> Path:
        ...
    


class ClassificationDataset(torchvision.datasets.ImageFolder):
    """
    YOLOv5 Classification Dataset.
    Arguments
        root:  Dataset path
        transform:  torchvision transforms, used by default
        album_transform: Albumentations transforms, used if installed
    """
    def __init__(self, root, augment, imgsz, cache=...) -> None:
        ...
    
    def __getitem__(self, i): # -> tuple[Unknown | Mat | Any, Unknown]:
        ...
    


def create_classification_dataloader(path, imgsz=..., batch_size=..., augment=..., cache=..., rank=..., workers=..., shuffle=...): # -> InfiniteDataLoader:
    ...

